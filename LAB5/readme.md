
# Robot Sensing and Navigation: LAB 5 Report

## Description

This repository documents the results and findings from the "Robot Sensing and Navigation" project, specifically focusing on LAB 5. The project delves into camera calibration and its significance in enhancing image interpretation for robotic systems.

### Camera Calibration

Camera calibration involves determining the intrinsic and extrinsic parameters of a camera. Intrinsic parameters, like focal length and lens distortion, define internal camera characteristics, while extrinsic parameters describe the camera's position and orientation in 3D space. Calibration corrects distortions, allowing accurate measurement of object size, distance, and position. The process is crucial in computer vision applications such as object recognition, stereo vision, and augmented reality.

### Undistortion

Undistortion is the correction of lens-induced distortion in images. By utilizing the camera's intrinsic parameters, such as focal length and distortion coefficients, distortions are modeled and corrected. This enhances the accuracy of measurements and overall quality of computer vision applications relying on undistorted images.

### LSC Mural

A panorama of the Latino Student Center was generated by taking six images from various angles, undistorting them using camera parameters. Despite some alignment issues, the resulting panorama provides an impressive view of the center.

### Ruggles Mosaic

Two approaches with 50% and 15% image overlap were employed to capture a mural in Ruggles. The project highlights the impact of overlap percentage on image stitching quality, showcasing the trade-offs between accuracy and capturing larger scenes.

### Cinder Wall

A high-quality panorama of a Cinder wall was created using seven images with varying overlap percentages. The Harris corner detection algorithm was employed, emphasizing the importance of feature points in achieving precise image stitching.

## Setup and Requirements

### Clone the Repository

Open your terminal or command prompt and run the following command to clone the repository:

 ```bash
    git clone https://github.com/ghime-u/EECE5554.git
    cd path/to/EECE5554
 ```

### Instructions

1. Change the \`imageFolder\` variable to the desired mural directory (e.g., 'LSC', 'Ruggles50', 'Ruggles15', or 'Cinder_wall').
2. Run \`main.m\` to create a mosaic panorama from the images in the specified folder.
3. Adjust parameters such as \`tile\` and \`tol\` for better results.

### Output

- Mosaic panorama will be displayed.

### Additional Information

- The script uses a Harris corner detector to find interest points.
- Subpixel precision and convolution optimizations are applied.

## Harris Corner Detector Function

### Instructions

1. Utilizes the \`harris.m\` function for Harris corner detection.
2. Modify parameters or use as a standalone function.

## Convolution Function

### Instructions

1. The \`convolve2.m\` function is used for 2D convolution.
2. Parameters and usage are explained in the function comments.

## Additional Notes

- Ensure the required images are in the correct folders.
- Adjust paths and directories as needed in the script.
- Refer to comments in the code for further details.

## Conclusion

In conclusion, the project emphasizes the crucial role of camera calibration in obtaining accurate and high-quality images for image stitching. Feature detection algorithms, like Harris corners, play a vital role in creating well-aligned panoramas with precise image stitching. Optimization of feature points and overlap percentage significantly influences the final output, enabling successful image stitching and resulting in visually striking panoramic images with high detail and resolution.

## Reference

[MatLab Vision Documentation](https://www.mathworks.com/help/vision/ug/feature-based-panoramic-image-stitching.html?searchHighlight=panorama&s_tid=doc_srchtitle)

